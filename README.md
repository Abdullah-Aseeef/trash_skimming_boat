# ğŸ§¹ Trash Skimming Robot for Water Bodies

This repository contains code, models, and evaluation workflows for a trash detection system aimed at identifying floating waste in water bodies. The system uses the YOLO object detection architecture and is designed for integration with an autonomous trash-skimming robot.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ notebooks/                  # Jupyter notebooks (baseline, improvements, visualizations)
â”‚   â”œâ”€â”€ baseline.ipynb
â”‚   â””â”€â”€ improved_model.ipynb
â”œâ”€â”€ src/                        # Core Python scripts
â”‚   â”œâ”€â”€ boat/                        # Python scripts to handle boat's hardware/movement
â”‚   â”‚   â”œâ”€â”€ LaptopCameraControl.py
â”‚   â”‚   â””â”€â”€ JetsonCameraControl.py
â”‚   â”œâ”€â”€ miscellaneous/                  # Scripts for dataset annotation format conversion
â”‚   â”‚   â”œâ”€â”€ convert_XML_annotations.py
â”‚   â”‚   â”œâ”€â”€ convert_XML_annotations_2.py
â”‚   â”‚   â””â”€â”€ convert_multiclass_annotations.py
â”œâ”€â”€ models/                     # Trained YOLO models
â”‚   â”œâ”€â”€ baseline_YOLOv12s.pt
â”‚   â”œâ”€â”€ improved_YOLOv12s.pt
â”‚   â””â”€â”€ improved_YOLOv12n.pt
â”œâ”€â”€ results/                    # Model Training and evaluation results
â”‚   â”œâ”€â”€ yolo12vs-results/
â”‚   â”œâ”€â”€ yolo12vn-results/
â”‚   â””â”€â”€ annotated_videos/       # Videos annotated using the improved model
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ§  Project Objective

To detect and classify floating trash in water bodies using YOLO-based object detection. The aim is to support real-time deployment on edge devices (e.g., Jetson Nano) for robotic waste removal applications.

---

## ğŸ—ï¸ Methodology

### Baseline

* **Model:** YOLOv12 (custom trained on water-trash dataset)
* **Data:** 3,798 annotated images, Pascal VOC format, 19 overlapping trash classes
* **Metrics:** Precision, Recall, Accuracy, F1 Score

### Improvements

* Refined trash label set for better consistency
* IoU-based evaluation to distinguish overlapping and missed detections
* Video annotation pipeline for real-world frame-by-frame assessment

---

## ğŸ¯ Results Summary

| Metric    | Baseline YOLO |
| --------- | ------------- |
| Accuracy  | 30.4%         |
| Precision | 57.6%         |
| Recall    | 39.1%         |
| F1 Score  | 46.6%         |

### Challenges Identified

* Poor detection of small or reflective objects
* False positives on background elements and water reflections
* Inconsistencies due to lighting, weather, and camera angle

---

## ğŸ–¼ï¸ Visualizations

* **Bounding Boxes:** Red = Ground Truth, Green = Predicted
* **Annotated Videos:** Found in `results/annotated_videos/*`

---

## ğŸ“¹ Video Annotation Pipeline

1. Load video frame-by-frame with OpenCV
2. Perform inference using YOLO
3. Draw bounding boxes around trash detections
4. Save annotated frames into output video

---

## ğŸ“¥ Dataset Download

You can download the full annotated dataset (3,798 images in Pascal VOC format across 19 trash classes) from our [Google Drive folder](https://drive.google.com/drive/folders/1ZbxAAX6zW6dkYCFI0oDsz_aC7dxq5Ohy?usp=share_link).

---


## ğŸ¤– Hardware Integration

* Scripts for controlling laptop and Jetson Nano cameras:

  * `LaptopCameraControl.py`
  * `JetsonCameraControl.py`
* These support live inference and testing on embedded systems.

---

## ğŸ“œ License

MIT License. See `LICENSE` file for more details.

---

## ğŸ‘¥ Contributors

* Muhammad Abdullah 
* Zaeem Mohtashim Khan
* Model architecture based on [Ultralytics YOLO](https://github.com/ultralytics/ultralytics)


